12/26/2018 9:40:21 PM 
--------------------------------------
##第1章 Elasticsearch集群入门，介绍什么是全文检索、Apache Lucene、文本分析、如何运行和配置Elasticsearch。最后，还会说明如何以最基本的方式索引和搜索数据。
##第2章 索引，展示索引的工作原理，如何创建索引结构，可以使用什么样的数据类型，如何加速索引，什么是段（segment），合并（merging）是如何工作的，什么是路由（routing）。
##第3章 搜索，介绍Elasticsearch的全文搜索功能。我们讨论如何查询，查询的工作原理，有哪些基本查询和复合查询。除此之外，本章还将展示如何过滤查询结果，如何高亮显示以及修改查询结果的排序。
##第4章 扩展索引结构，讨论如何索引更复杂的数据结构。本章讨论如何索引树状数据类型和关系型数据，以及修改索引的结构。
##第5章 更好的搜索，涵盖Apache Lucene的评分功能，以及使用Elasticsearch的脚本功能和语言分析器如何影响评分 。
##第6章 超越全文检索，详细介绍聚合框架的功能、切面以及如何使用Elasticsearch实现拼写检查和自动完成功能。此外，读者将学会如何索引二进制文件、处理地理空间数据，以及高效处理大数据集。
##第7章 深入Elasticsearch集群，讨论节点发现机制，恢复和时光之门（Gateway）模块，高查询和高索引用例场景下的模板和集群。
##第8章 集群管理，涵盖Elasticsearch备份功能、集群监控、再平衡和移动分片。除此之外，你还会学到如何使用热身功能和别名，安装插件，以及使用更新API来更新集群设置。
------------------------------------------
12/26/2018 9:40:29 PM 

Lucene词汇表和架构
文档（document）：索引和搜索时使用的主要数据载体，包含一个或多个存有数据的字段。
 字段（field）：文档的一部分，包含名称和值两部分。
 词（term）：一个搜索单元，表示文本中的一个词。
 标记（token）：表示在字段文本中出现的词，由这个词的文本、开始和结束偏移量以及类
型组成。
Apache Lucene将所有信息写到一个称为倒排索引（inverted index）的结构中。
倒排索引建立索引中词和文档之间的映射。你可以把倒排索引看成这样
一种数据结构，其中的数据是面向词而不是面向文档的

输入数据分析

分析的工作由分析器完成，它由一个分词器（tokenizer）和零个或多个标记过滤器（token filter）
组成，也可以有零个或多个字符映射器（character mapper）。
Lucene中的分词器把文本分割成多个标记，基本就是词加上一些额外信息，比如该词在原始
文本中的位置和长度。分词器的处理结果称为标记流（token stream），它是一个接一个的标记，
准备被过滤器处理。
除了分词器，Lucene分析器包含零个或多个标记过滤器，用来处理标记流中的标记。

 小写过滤器（lowercase filter）：把所有的标记变成小写。
 同义词过滤器（synonyms filter）：基于基本的同义词规则，把一个标记换成另一个同义的
标记。
 多语言词干提取过滤器（multiple language stemming filter）：减少标记（实际上是标记中
的文本部分），得到词根或者基本形式，即词干。

关于索引和查询分析，你应该记住的是，索引应该和查询词匹配。如果它们不匹配，Lucene
不会返回所需文档。

评分和查询相关性
得分是根据文档
和查询的匹配度用计分公式计算的结果。

，Elasticsearch和Lucene计算的分数值越高，意味着文档越相关
1.2 Elasticsearch 基础

1.2.1 数据架构的主要概念

索引（index）是Elasticsearch对逻辑数据的逻辑存储，所以它可以分为更小的部分。你可以把
索引看成关系型数据库的表。然而，索引的结构是为快速有效的全文索引准备的，特别是它不存
储原始值。如

存储在Elasticsearch中的主要实体叫文档（document）。用关系型数据库来类比的话，一个文
档相当于数据库表中的一行记录。当

文档由多个字段组成，每个字段可能多次出现在一个文档里，这样的字段叫多值字段
（multivalued）。每个字段有类型，如文本、数值、日期等。字段类型也可以是复杂类型，一个字
段包含其他子文档或者数组。字段类型在Elasticsearch中很重要，因为它给出了各种操作（如分
析或排序）如何被执行的信息。

从客户端的角度看，文档是一个JSON
对象。每个文档存储在一个
索引中并有一个Elasticsearch自动生成的唯一标识符和文档类型。文

。文档类型让我们轻易地区分单个索引中的不同对象每个文档可以有不同
的结构，但

分析的过程：为建索引和搜索准备输入文本
。文
档中的每个字段都必须根据不同类型做相应的分析
每一个文档类型都有
自己的映射，即使我们没有明确定义。

道Elasticsearch把数据存储在一个或多个索引上，每个索引包含各种类型
的文档。我们也知道了每个文档有很多字段，映射定义了Elasticsearch如何对待这些字段。

这些服务器称为集群
（cluster），形成集群的每个服务器称为节点（node）。

数据可以分为较小的称为分片（shard）的部分（其
中每个分片都是一个独立的Apache Lucene索引）。

为了提高查询吞吐量或实现高可用性，可以使用分片副本。副本（replica）只是一个分片的
精确复制，每个分片可以有零个或多个副本。换句话说，Elasticsearch可以有许多相同的分片，
其中之一被自动选择去更改索引操作。这种特殊的分片称为主分片（primary shard），其余称为副
本分片（replica shard）。在主分片丢失时，例如该分片数据所在服务器不可用，集群将副本提升
为新的主分片。

Elasticsearch处理许多节点。集群的状态由时光之门控制。默认情况下，每个节点都在本地
存储这些信息，并且在节点中同步。

发送一个新的文档给集群时，你指定一个目标索引并发送给它的任意一个节点。这个节点知
道目标索引有多少分片，并且能够确定哪个分片应该用来存储你的文档。

尝试用文档标识符来获取文档时，发送查询到一个节点，该节点使用同样的路由算法来决定
持有文档的节点和分片，然后转发查询，获取结果，并把结果发送给你。另一方面，查询过程更
为复杂。除非使用了路由，查询将直接转发到单个分片，否则，收到查询请求的节点会把查询转
发给保存了属于给定索引的分片的所有节点，并要求与查询匹配的文档的最少信息（默认情况下
是标识符和得分）。这个过程称为发散阶段（scatter phase）。收到这些信息后，该聚合节点（收到
客户端请求的节点）对结果排序，并发送第2个请求来获取结果列表所需的文档（除了标识符和
得分以外的所有信息）。这个阶段称为收集阶段（gather phase）。这个阶段执行完毕后，结果返回
到客户端。

整个配置位于config
目录下，可以看到两个文件：elasticsearch.yml（或elasticsearch.json，如果有的话会被使用）和
logging.yml。第一个文件负责设置服务器的默认配置值。

第2个文件（logging.yml）定义了多少信息写入系统日志，定义了日志文件，并定期创建新
文件。只有在调整监控、备份方案或系统调试时，才需要修改。然而如果想有一份更详细的日志，
就需要相应调整。

 Windows：elasticsearch.bat。
开http://127.0.0.1:9200来检查搜索是否就绪，浏览器将显示类似下面这样的代码片段：

现在，将使用cURL程序。例如，要检查集群健康度，会使用以下命令：
curl -XGET http://127.0.0.1:9200/_cluster/health?pretty 

Elasticsearch自动形成了一个新的双节点集群。

 如果节点是连接到控制台，按下Ctrl+C。
 第二种选择是通过发送TERM信号杀掉服务器进程（参考Linux上的kill命令和Windows
上的任务管理器）。
 第三种方法是使用REST API。
现在着重介绍第三种方法。可以执行以下命令来关掉整个集群：
curl -XPOST http://localhost:9200/_cluster/nodes/_shutdown
为关闭单一节点，假如节点标识符是BlrmMvBdSKiCeYGsiHijdg，可以执行下面的命令：
curl –XPOST
http://localhost:9200/_cluster/nodes/BlrmMvBdSKiCeYGsiHijdg/_shutdown 

节点的标识符可以在日志中看到，或者使用_cluster/nodes API，命令如下：
curl -XGET http://localhost:9200/_cluster/nodes/ 

为了将Elasticsearch
安装成一个Linux系统服务，将使用Elasticsearch service wrapper，

service.bat install
你会被问及操作权限，允许脚本运行，Elasticsearch就被安装成一个Windows服务。
如果你想看看所有被service.bat脚本文件暴露出来的命令，在相同目录下执行：
service.bat
例如，为了启动Elasticsearch，可执行如下命令：
service.bat start 

，GET用来获得请求对象的当前
状态，POST来改变对象的当前状态，PUT创建一个对象，而DELETE销毁对象，另外还有个HEAD
请求仅仅用来获取对象的基础信息。

所有的数据，即每个文档，都有定义好的索引和类型。
每个文档可以包含一个或多个字段来保存数据。首先展示如何使用Elasticsearch为一个简单文档
建立索引。

我们自己指定了文档标识符。然而，Elasticsearch可以自动生成它

我们想更改列表中的文档索引，而不是创建一个新的实体，所以使用POST而不是PUT

现在尝试通过标识符检索。首先执行以下命令：
curl -XGET http://localhost:9200/blog/article/1 

更新索引中的文档是一项更复杂的任务。在内部，Elasticsearch必须首先获取文档，从
_source属性获得数据，删除旧的文件，更改_source属性，然后把它作为新的文档来索引。
\

curl -XPOST http://localhost:9200/blog/article/1/_update -d '{
 "script": "ctx._source.content = \"new content\""
}' 
是请记住，为了使用更新功能，需要使用_source字段
想增加文档中的counter字段，而该字段不存在，你可以
在请求中使用upsert节来提供字段的默认值。看


需要使用DELETE请求类型发送一个适当的HTTP请求。例如，要删除示例文档，运行以下命令：
curl -XDELETE http://localhost:9200/blog/article/1 

这个版本是递增的。默认情况下，
Elasticsearch在添加、更改或删除文档时都会递增版本号
使用
乐观锁，Elasticsearch保证数据的准确性，尝试写入一个已更改的文档将会失败。

Elasticsearch也可基于我们提供给它的版本号
curl -XPUT 'localhost:9200/library/book/1?version=123456' -d {...} 
进入Elasticsearch查询的详细信息之前，先使用其中简单的URI请求来搜索。

URI查询中的字符参数
(1) 查询
参数q用来指定我们希望文件匹配的查询条件。
 默认查询字段
使用df参数，可以指定在q参数中没有字段时应该默认使用的字段。默认情况下，将使用_all
字段。

(3) 分析器
可以将analyzer属性定义用于分析查询的分析器名称。默认情况下，索引阶段对字段内容
做分析的分析器将用来分析我们的查询。
(4) 默认操作符
Default_operator属性可以设置成OR或AND，用来指定用于查询的默认布尔运算符。默认
情况下，它设置为OR，意味着只要有一个查询条件匹配，就将返回文档。此参数设置为AND时，
所有查询条件都匹配时才会返回文档。
(5) 查询解释
如果将explain参数设置为true，Elasticsearch将在结果的每个文档里包括额外的解释信息，
如文档是从哪个分片上获取的、计算得分的详细信息
默认情况下，返回的每个文档中，Elasticsearch将包括索引名称、类型名称、文档标识符、
得分和_source字段。我们可以修改这个行为，通过添加fields参数并指定一个以逗号分隔的
字段名称列表。这
(7) 结果排序
通过使用sort参数，可以指定自定义排序。Elasticsearch的默认行为是把返回文档按它们的
得分降序排列。如果想有不同的排序，则需要指定sort参数。例如，添加sort=published:desc，
文档将按published字段降序排序；添加sort=published:asc，则告诉Elasticsearch把文档按
published字段升序排序。
(8) 搜索超时
默认情况下，Elasticsearch没有查询超时，但你可能希望查询在一段时间（比如5秒）后超时。
Elasticsearch允许你设置timeout参数。查询将执行到给定的timeout值，在那一刻，收集的结
果将返回。把timeout=5s添加到你的查询，就可指定一个5秒的超时。
(9) 查询结果窗口
Elasticsearch允许你指定结果窗口（应返回的结果列表中文件的范围）。有两个参数用来指定
结果窗口大小：size和from。size参数默认为10，它定义了返回结果的最大数量。from参数的
默认值为0，它指定结果应该从哪个记录开始返回。为了从第11个开始返回5个文档，我们将在查
询中添加以下参数：size=5&from=10
(10) 搜索类型
URI查询允许使用search_type参数指定搜索类型，搜索类型默认为query_then_fetch。
我们可以使用以下6个值：
 dfs_query_then_fetch
 dfs_query_and_fetch
 query_then_fetch
 query_and_fetch
 count
 scan
(11) 小写扩展词
一些查询使用查询扩展，比如前缀查询（prefix query），3
lowercase_expanded_terms属性来定义扩展词是否应该被转为小写。默认该属性为true，意
味着扩展词将被小写。
(12) 分析通配符和前缀
默认情况下，通配符查询和前缀查询不会被分析。如果要更改此行为，可以把analyze_
ildcard属性设置为true。
我们传到Lucene的查询被查询解析器分为词（term）和操作符（operator）。先从词开始，你
可以区分两种类型的词：单词和短语

例如，操作符+告诉Lucene给定部分必须在文档中
匹配。操作符-正相反，查询的这一部分不能出现在文档中。查询中既没有+又没有－操作符的部
分将被视为可以匹配、但非强制性的查询。

也可以用括号来组合多个词，如下面的查询：
title:(crime punishment)
还可以使用^操作符接上一个值来助推（boost）①一个词，比如以下查询：
12/27/2018 11:17:41 PM 